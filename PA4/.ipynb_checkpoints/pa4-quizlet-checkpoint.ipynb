{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Quizlet! \n",
    "\n",
    "Can you write a program to answer quiz questions?  \n",
    "\n",
    "Do you ever wish you could write a program to take quizzes or tests for you? In this assignment, you’ll do just that! In particular, you’ll leverage word embeddings to write a program that can answer various multiple choice and true/false quiz questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Embeddings\n",
    "You’ll be using subset of ~4k 50-dimensional GloVe embeddings trained on Wikipedia articles. The GloVe (Global Vectors) model learns vector representations for words by looking at global word-word co-occurrence statistics in a body of text and learning vectors such that their dot product is proportional to the probability of the corresponding words co-occuring in a piece of text. The GloVe model was developed right here at Stanford, and if you’re curious you can read more about it [here](https://nlp.stanford.edu/projects/glove/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify this cell, please just run it!\n",
    "import quizlet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Mission\n",
    "The assignment consists of four parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Synonyms\n",
    "For this section, your goal is to answer questions of the form:\n",
    "\n",
    "```\n",
    "  What is a synonym for warrior?  \n",
    "  a) soldier  \n",
    "  b) sailor  \n",
    "  c) pirate  \n",
    "  d) spy  \n",
    "```\n",
    "\n",
    "You are given as input a word and a list of candidate choices. Your goal is to return the choice you think is the synonym. You’ll first implement two similarity metrics - euclidean distance and cosine similarity - then leverage them to answer the multiple choice questions!\n",
    "\n",
    "Specifically, you will implement the following 4 functions:\n",
    "\n",
    "* **euclidean_distance()**: calculate the euclidean distance between two vectors. Note: you’ll only use this metric in Part 1. For the rest of the assignment, you'll only use cosine similarity.\n",
    "* **cosine_similarity()**: calculate the cosine similarity between two vectors. You’ll be using this helper function throughout the other parts of the assignment as well, so you’ll want to get it right!\n",
    "* **find_synonym()**: given a word, a list of 4 candidate choices, and which similarity metric to use, return which word you think is the synonym! The function takes in `comparison_metric` as a parameter: if its value is `euc_dist`, you'll use Euclidean distance as the similarity metric; if its value is `cosine_sim`, you'll use cosine similarity as the metric.\n",
    "* **part1_written()**: you’ll find that finding synonyms with word embeddings works quite well, especially when using cosine similarity as the metric. However, it’s not perfect. In this function, you’ll look at a question that your `find_synonyms()` function (using cosine similarity) gets wrong, and answer why you think this might be the case. Please return your answer as a string in this function.\n",
    "\n",
    "Note: for the rest of the assignment, you'll only use cosine similarity as the comparison metric. You won't use the euclidean distance function anymore.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    '''\n",
    "    Calculates and returns the cosine similarity between vectors v1 and v2\n",
    "    Arguments:\n",
    "        v1, v2 (numpy vectors): vectors\n",
    "    Returns:\n",
    "        cosine_sim (float): the cosine similarity between v1, v2\n",
    "    '''\n",
    "    cosine_sim = 0\n",
    "    #########################################################\n",
    "    ## TODO: calculate cosine similarity between v1, v2    ##\n",
    "    #########################################################\n",
    "\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    #########################################################\n",
    "    return cosine_sim   \n",
    "\n",
    "def euclidean_distance(v1, v2):\n",
    "    '''\n",
    "    Calculates and returns the euclidean distance between v1 and v2\n",
    "\n",
    "    Arguments:\n",
    "        v1, v2 (numpy vectors): vectors\n",
    "\n",
    "    Returns:\n",
    "        euclidean_dist (float): the euclidean distance between v1, v2\n",
    "    '''\n",
    "    euclidean_dist = 0\n",
    "    #########################################################\n",
    "    ## TODO: calculate euclidean distance between v1, v2   ##\n",
    "    #########################################################\n",
    "\n",
    "    #########################################################\n",
    "    ## End TODO                                           ##\n",
    "    #########################################################\n",
    "    return euclidean_dist                 \n",
    "\n",
    "def find_synonym(word, choices, embeddings, comparison_metric):\n",
    "    '''\n",
    "    Answer a multiple choice synonym question! Namely, given a word w \n",
    "    and list of candidate answers, find the word that is most similar to w.\n",
    "    Similarity will be determined by either euclidean distance or cosine\n",
    "    similarity, depending on what is passed in as the comparison_metric.\n",
    "\n",
    "    Arguments:\n",
    "        word (string): word\n",
    "        choices (list of strings): list of candidate answers\n",
    "        embeddings (map): map of words (strings) to their embeddings (np vectors)\n",
    "        comparison_metric (string): either 'euc_dist' or 'cosine_sim'. \n",
    "            This indicates which metric to use - either euclidean distance or cosine similarity.\n",
    "            With euclidean distance, we want the word with the lowest euclidean distance.\n",
    "            With cosine similarity, we want the word with the highest cosine similarity.\n",
    "\n",
    "    Returns:\n",
    "        answer (string): the word in choices most similar to the given word\n",
    "    '''\n",
    "    answer = None\n",
    "    #########################################################\n",
    "    ## TODO: find synonym                                  ##\n",
    "    #########################################################\n",
    "\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    ######################################################### \n",
    "    return answer\n",
    "\n",
    "def part1_written():\n",
    "    '''\n",
    "    Finding synonyms using cosine similarity on word embeddings does fairly well!\n",
    "    However, it's not perfect. In particular, you should see that it gets the last\n",
    "    synonym quiz question wrong (the true answer would be positive):\n",
    "\n",
    "    30. What is a synonym for sanguine?\n",
    "        a) pessimistic\n",
    "        b) unsure\n",
    "        c) sad\n",
    "        d) positive\n",
    "\n",
    "    What word does it choose instead? In 1-2 sentences, explain why you think \n",
    "    it got the question wrong.\n",
    "    '''\n",
    "    #########################################################\n",
    "    ## TODO: replace string with your answer               ##\n",
    "    ######################################################### \n",
    "    answer = \"\"\"\n",
    "    TODO fill this in\n",
    "    \"\"\"\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    ######################################################### \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"This will create a class to test the functions you implemented above. If you are curious, \n",
    "you can see the code for this in quizlet.py but it is not required. If you run this cell,\n",
    "we will load the test data for you and run it on your functions to test your implementation.\n",
    "\n",
    "You should get an accuracy of 66% with euclidean distance and 83% with cosine distance\n",
    "\"\"\"\n",
    "\n",
    "part1 = quizlet.Part1_Runner(find_synonym, part1_written)\n",
    "part1.evaluate(True)  # To only print the scores, pass in False as an argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Analogies\n",
    "For this section, your goal is to answer questions of the form:\n",
    "\n",
    "```\n",
    "  man is to king as woman is to ___?  \n",
    "  a) princess  \n",
    "  b) queen  \n",
    "  c) wife  \n",
    "  d) ruler   \n",
    "```\n",
    "\n",
    "Namely, you are trying to find the word bb that completes the analogy a:b → aa:bb. You will take as input three words, a, b, aa, and a list of candidate choices and return the choice you think completes the analogy.\n",
    "\n",
    "One of the neat properties of embeddings is their ability to capture relational meanings. In fact, for the analogy **man:king → woman:queen** above, we have that the vector:\n",
    "\n",
    "`vector('king') - vector('man') + vector('woman')`\n",
    "\n",
    "is a vector close to  `vector('queen')`. Make sure that when completing these analogies, you are following the **same logical order** as the example above in order to align with our test set. You’ll leverage this pattern to try to answer the quizlet questions!\n",
    "\n",
    "Specifically, you will implement the following function:\n",
    "\n",
    "* **find_analogy_word()**: given a, b, and aa, find the best word in a list of candidate choices that completes the analogy (leveraging cosine similarity as your similarity metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogy_word(a, b, aa, choices, embeddings):\n",
    "    '''\n",
    "    Find the word bb that completes the analogy: a:b -> aa:bb\n",
    "    A classic example would be: man:king -> woman:queen\n",
    "\n",
    "    Note: use cosine similarity as your similarity metric\n",
    "\n",
    "    Arguments:\n",
    "        a, b, aa (strings): words in the analogy described above\n",
    "        choices (list): list of strings for possible answer\n",
    "        embeddings (map): map of words (strings) to their embeddings (np vectors)\n",
    "\n",
    "    Returns:\n",
    "        answer: the word bb that completes the analogy\n",
    "    '''\n",
    "    answer = None\n",
    "    #########################################################\n",
    "    ## TODO: analogy                                       ##\n",
    "    #########################################################\n",
    "\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    #########################################################\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": [
    "# You should get an accuracy of 16%\n",
    "\n",
    "part2 = quizlet.Part2_Runner(find_analogy_word)\n",
    "part2.evaluate(True) # To only print the scores, pass in False as an argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Sentence Similarity\n",
    "For this section, your goal is to answer questions of the form:\n",
    "\n",
    "```\n",
    "    True/False: the following two sentences are semantically similar:\n",
    "      1. he later learned that the incident was caused by the concorde's sonic boom\n",
    "      2. he later found out the alarming incident had been caused by concorde's powerful sonic boom\n",
    "```\n",
    "\n",
    "Namely, you take in 2 sentences as input, and output either true or false (ie, a label of 1 or 0). To do this, you will create a sentence embedding that represents each sentence in vector form, then apply cosine similarity to compute the similarity between the two sentence embeddings. If they have a high enough similarity, you’ll guess \"True\" and otherwise \"False\".\n",
    "\n",
    "To accomplish this, you’ll first turn each sentence into a single vector embedding. There are a few different ways you can do this. For this assignment, we’ll look at two approaches:\n",
    "\n",
    "* **Simple sum**: Sum the word embeddings of each individual word in the sentence. This resulting vector is the sentence embedding vector.\n",
    "* **Sum with POS weighting**: Take a weighted sum of the individual word vectors, where the weighting depends on the part of speech (POS) of that given word. Each POS (ie, verb, noun, adjective, etc) has a different scalar weight associated with it. We multiply each word vector by the scalar weight associated with its part of speech, then sum these weighted vectors.\n",
    "\n",
    "Specifically, you will implement the following 2 functions:\n",
    "\n",
    "* **get_embedding()**: given a sentence (string), return the sentence embedding (vector). The function also takes in the parameter `use_POS`:\n",
    "    * if `use_POS` is false (regular case), leverage method 1 above - simply the sum of the word embeddings for each word in the sentence (ignoring words that don’t appear in our vocabulary).\n",
    "    * if `use_POS` is true, leverage method 2 - use a weighted sum, where we weight each word by a scalar that depends on its part of speech tag.\n",
    "* **get_similarity()**: given two sentences, find the cosine similarity between their corresponding sentence embeddings.\n",
    "\n",
    "Helpful hints:\n",
    "\n",
    "* We’ve given you a map `POS_weights` that maps part of speech tags to their associated weight. For example, `POS_weights['NN'] = 0.8` (where NN is the POS tag for noun).\n",
    "* You may skip words that either (1) are not in our embeddings or (2) have a POS tag that is not in `POS_weights` .\n",
    "* To get a list of all the words in the sentence, use nltk's word_tokenize function.\n",
    "\n",
    "  ```\n",
    "  >>> sentence = \"this is a sentence\"\n",
    "  >>> word_tokens = word_tokenize(sentence)\n",
    "  >>> word_tokens\n",
    "  ['this', 'is', 'a', 'sentence']\n",
    "  ```\n",
    "  \n",
    "* To get the POS tags for each word in a sentence, you can use nltk.pos_tag. To use it, you provide a list of words in a sentence, and it returns a list of tuples, where the first element is the word and the second is its corresponding POS tag. **For this PA, make sure that you pass in the entire sentence to a single call to nltk.pos_tag; do not call  nltk.pos_tag separately on each word in the sentence.** This is because some words can be multiple parts of speech (for example, \"back\" can be a noun or a verb). Passing in the entire sentence allows for more context to figure out what POS tag a word should have.\n",
    "\n",
    "```\n",
    "    >>> tagged_words = nltk.pos_tag(word_tokens)\n",
    "    >>> tagged_words\n",
    "    [('this', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('sentence', 'NN')]`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def get_embedding(s, embeddings, use_POS=False, POS_weights=None):\n",
    "    '''\n",
    "    Returns vector embedding for a given sentence.\n",
    "\n",
    "    Hint:\n",
    "    - to get all the words in the sentence, you can use nltk's `word_tokenize` function\n",
    "        >>> list_of_words = word_tokenize(sentence_string)\n",
    "    - to get part of speech tags for words in a sentence, you can use `nltk.pos_tag`\n",
    "        >>> tagged_tokens = nltk.pos_tag(list_of_words)\n",
    "    - you can read more here: https://www.nltk.org/book/ch05.html\n",
    "\n",
    "    Arguments:\n",
    "        s (string): sentence\n",
    "        embeddings (map): map of words (strings) to their embeddings (np vectors)\n",
    "        use_POS (boolean): flag indicating whether to use POS weightings when\n",
    "            calculating the sentence embedding\n",
    "        POS_weights (map): map of part of speech tags (strings) to their weights (floats),\n",
    "            it is only to be used if the use_POS flag is true\n",
    "\n",
    "    Returns:\n",
    "        embed (np vector): vector embedding of sentence s\n",
    "    '''\n",
    "    embed = np.zeros(embeddings.vector_size)\n",
    "    #########################################################\n",
    "    ## TODO: get embedding                                 ##\n",
    "    #########################################################\n",
    "\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    #########################################################\n",
    "    return embed\n",
    "\n",
    "def get_similarity(s1, s2, embeddings, use_POS, POS_weights=None):\n",
    "    '''\n",
    "    Given 2 sentences and the embeddings dictionary, convert the sentences\n",
    "    into sentence embeddings and return the cosine similarity between them.\n",
    "\n",
    "    Arguments:\n",
    "        s1, s2 (strings): sentences\n",
    "        embeddings (map): map of words (strings) to their embeddings (np vectors)\n",
    "        use_POS (boolean): flag indicating whether to use POS weightings when\n",
    "            calculating the sentence embedding\n",
    "        POS_weights (map): map of part of speech tags (strings) to their weights (floats),\n",
    "            it is only to be used if the use_POS flag is true\n",
    "\n",
    "    Returns:\n",
    "        similarity (float): cosine similarity of the two sentence embeddings\n",
    "    '''\n",
    "    similarity = 0\n",
    "    #########################################################\n",
    "    ## TODO: compute similarity                            ##\n",
    "    #########################################################\n",
    "\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    #########################################################\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": [
    "# You should get an accuracy of 78% without POS weights, and 88% with.\n",
    "\n",
    "part3 = quizlet.Part3_Runner(get_similarity)\n",
    "part3.evaluate(True) # To only print the scores, pass in False as an argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Exploration\n",
    "In this section, you'll do an exploration question. Specifically, you'll implement the following 2 functions:\n",
    "\n",
    "* **occupation_exploration()**: given a list of occupations, find the top 5 occupations with the highest cosine similarity to the word \"man\", and the top 5 occupations with the highest cosine similarity to the word \"woman\".\n",
    "* **part4_written()**: look at your results from the previous exploration task. What do you observe, and why do you think this might be the case? Write your answer within the function by returning a string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occupation_exploration(occupations, embeddings):\n",
    "    '''\n",
    "    Given a list of occupations, return the 5 occupations that are closest\n",
    "    to 'man', and the 5 closest to 'woman', using cosine similarity between\n",
    "    corresponding word embeddings as a measure of similarity.\n",
    "\n",
    "    Arguments:\n",
    "        occupations (list): list of occupations (strings)\n",
    "        embeddings (map): map of words (strings) to their embeddings (np vectors)\n",
    "\n",
    "    Returns:\n",
    "        top_man_occs (list): list of 5 occupations (strings) closest to 'man'\n",
    "        top_woman_occs (list): list of 5 occuptions (strings) closest to 'woman'\n",
    "            note: both lists should be sorted, with the occupation with highest\n",
    "                  cosine similarity first in the list\n",
    "    '''\n",
    "    top_man_occs = []\n",
    "    top_woman_occs = []\n",
    "    #########################################################\n",
    "    ## TODO: get 5 occupations closest to 'man' & 'woman'  ##\n",
    "    #########################################################\n",
    "\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    #########################################################\n",
    "    return top_man_occs, top_woman_occs\n",
    "\n",
    "def part4_written():\n",
    "    '''\n",
    "    Take a look at what occupations you found are closest to 'man' and\n",
    "    closest to 'woman'. Do you notice anything curious? In 1-2 sentences,\n",
    "    describe what you find, and why you think this occurs.\n",
    "    '''\n",
    "    #########################################################\n",
    "    ## TODO: replace string with your answer               ##\n",
    "    ######################################################### \n",
    "    answer = \"\"\"\n",
    "    TODO fill this in\n",
    "    \"\"\"\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    ######################################################### \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": [
    "part4 = quizlet.Part4_Runner(occupation_exploration, part4_written)\n",
    "part4.evaluate() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Entity Representation\n",
    "\n",
    "Entities can be detected in text using a Named Entity Recognition (NER) Model. Luckily many such models exist and can be employed off-the-shelf for decent performance. In this section, we will take a corpus of documents from Wikipedia and extract named entities from them by using the NER model from SpaCy.\n",
    "\n",
    "Once we've extracted entities, we might be interested in finding which ones are similar to each other. \n",
    "\n",
    "Like any other words, entities have have vector representations. However, since we are working with a fixed vocabulary, it is likely that we won't find all our entities in the vocabulary.\n",
    "    \n",
    "One simple way to create entity representations is to take the mean of the text description of the entity. In this assignment, for each entity we have a description from Wikipedia. You will implement a function that computes an entity representation by taking the mean of the embeddings of the description. Note that not all the words in the description are in our vocabulary, so skip those. Also, using embeddings of stop words might add noise to averaged embeddings, so let's skip those words as well. _Note: SpaCy token objects have an Token.is_stop field that you can use for this._\n",
    "\n",
    "Once we've computed embeddings for each entity, we might be interested in finding entities that are similar to each other. For each entity, let's find the top 5 most similar entities. _Note: For fast computation, you might want to vectorize your cosine similarity computation._\n",
    "\n",
    "We have a dataset of annotated similar entities. Let's see how well we do on this benchmark and then let's visually inspect our similar entities to see how coherent they seem. \n",
    "\n",
    "_Question: Do you see any patterns in entities that are similar? Do you see any systematic mistakes?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will use SpaCy to extact Named Entities\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities(paragraph):\n",
    "    '''\n",
    "    This function will be fed 1  paragraph at a time.\n",
    "    See the documentation for using the SpaCy API (https://spacy.io/) to convert \n",
    "    the paragraphs to Spacy Documents. The processing automatically runs an NER model.\n",
    "    You should be able to use a simple field on the Document object to return\n",
    "    the  entities in the paragraph.\n",
    "    https://spacy.io/usage/linguistic-features#named-entities\n",
    "    '''\n",
    "    spacy_paragraph = None\n",
    "    named_entities = []\n",
    "    #########################################################\n",
    "    ## Process paragraph with SpaCy and extract entities.  ##\n",
    "    #########################################################\n",
    "\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    #########################################################\n",
    "    return named_entities, spacy_paragraph\n",
    "    \n",
    "def compute_entity_representation(description, embeddings):\n",
    "    '''\n",
    "    For each entity, we will use the description to build an entity representation.\n",
    "    Use the embeddings as before to get an emebedding for each word in the description.\n",
    "    Note that the description is a Spacy.Document so access the raw text accordingly.\n",
    "    Note that you probably want to use lower case lookup in the embddings table.\n",
    "    Tak the mean of all words from the description that appear in the vocabulary and \n",
    "    that are NOT stop words.\n",
    "    Note: SpaCy Tokens have a Token.is_stop field.\n",
    "    '''\n",
    "    vector = None\n",
    "    #########################################################\n",
    "    ## TODO: Compute embedding for entity                  ##\n",
    "    #########################################################\n",
    "    \n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    #########################################################\n",
    "    return vector\n",
    "    \n",
    "def get_top_k_similar(entity, entity_embedding, options, top_k):\n",
    "    '''\n",
    "    For this function, you are given an entity name, the embedding for that entity,\n",
    "    and a dictionary of options ({entity_name: entity_embedding}). \n",
    "    Return the top k (string) entities that are most similar to the provided entity.\n",
    "    This function will be called many times and compared with many entities so you should \n",
    "    optimize your cosine similarity function. You can parallelize the computation using\n",
    "    a matrix multiplication.\n",
    "    \n",
    "    Arguments:\n",
    "        entity (string): text of an entity\n",
    "        entity_embedding (numpy array): the vector embedding for the entity\n",
    "        options (map {string -> numpy array}): similar to the above entity and embedding,\n",
    "            this is a dictionary of all the options to choose from.\n",
    "        top_k (int): size of return\n",
    "\n",
    "    Returns:\n",
    "        similar_entities (list of strings): this should be of size top_k\n",
    "    \n",
    "    '''\n",
    "    similar_entities = []\n",
    "    #########################################################\n",
    "    ## TODO: return similar k entities                     ##\n",
    "    #########################################################\n",
    "  \n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    #########################################################\n",
    "    return similar_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: You may want to put the below function and function call into a \n",
    "# loop to find a good threshold.\n",
    "\n",
    "def compute_entity_similarity(entity_representation_1, entity_representation_2):\n",
    "    '''\n",
    "    Compute the similarity between these two entities. Since we are doing a binary\n",
    "    classification task, you'll want to find a good threshold to convert from a \n",
    "    cosine similarity score to a boolean value.\n",
    "    '''\n",
    "    #########################################################\n",
    "    ## TODO: Compute similarity between two entities       ##\n",
    "    #########################################################\n",
    "    return False\n",
    "    #########################################################\n",
    "    ## End TODO                                            ##\n",
    "    #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": [
    "part5 = quizlet.Part5_Runner(extract_named_entities, compute_entity_representation,\n",
    "                            compute_entity_similarity, get_top_k_similar)\n",
    "\n",
    "# This part may take >10 seconds to complete\n",
    "part5.build_representations()\n",
    "\n",
    "# You should have found over 4,000 unique entity mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exploration"
    ]
   },
   "outputs": [],
   "source": [
    "# This is just overwriting the function in the runner class so you can run this \n",
    "# cell many times to test different thresholds.\n",
    "part5.compute_entity_similarity = compute_entity_similarity\n",
    "part5.evaluate(True)  # Pass in false to not print out top k similar entities \n",
    "\n",
    "# You should be able to get above 85% accuracy on the binary entity similarity task\n",
    "# You should be able to  get above 10% on the top 5 similar entities task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow up\n",
    "You may be surprised by the low accuracy on the top k task, but when you look at the output, you should see that the similar entities are reasonable. The dataset we are using wasn't designed to rank similar entities, rather only to do the binary  classification task. In this case our ground truth is quite noisy so the quantitative results may be misleading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:cs124] *",
   "language": "python",
   "name": "conda-env-cs124-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
